

# Overview

LLMs should not be used as tools to blindly follow and regurgate text but should instead empower users to learn new things, teach them how to do things they can't yet do. 

# Usage

## Mistral with Ollama

Install Ollama locally using `curl https://ollama.ai/install.sh | sh`
Then from the CLI to run the model `mistral` run `ollama run mistal`

## llamaCPP with Llama_index
Nothing to do.

