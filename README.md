

# Overview

LLMs should not be used as tools to blindly follow and regurgate text but should instead empower users to learn new things, teach them how to do things they can't yet do. 

# Usage
Working on an MVP using llama_index for the llm and RAG processing but with the plan on supporting other packages (ollama ...). Currently the only LLM for question / answer supported is llamaCPP and the embedding LLM is BGE fast downloaded from hugginface and the embedding database is a simple llama_index db that is kept in memory. This will be until  I can get a working pipeline that will serve as proof of concept and then I will revisit and optimize all the steps individually.  

